\documentclass[a4paper,12pt]{article}
\usepackage[a4paper,top=2.0cm, bottom=1.5cm, left=1.5cm, right=1.5cm]{geometry}

\usepackage[T2A]{fontenc}			
\usepackage[utf8]{inputenc}		
\usepackage[english,russian]{babel}	
\usepackage{amsmath,amsfonts,amssymb,amsthm,mathtools} 
\usepackage{wasysym}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{amsmath}
\usepackage{ mathrsfs }
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareGraphicsExtensions{.pdf, .png, .jpg}
\graphicspath{{}}


\begin{document}
	\section{Введение}
		\subsection{Основные понятия}
			Основная единица данных, рассматривающаяся в работе -- элемент одежды, далее будем называть его \textit{объектом} или \textit{элементом}, множество всех рассматриваемых объектов -- $\mathcal{X}$. 
			
			Каждый объект $X\in\mathcal{X}$ представим как пару $X = (I, T)$ соответственно изображения объекта (может отсутствовать) и его текстового описания(может быть пустым). 
			
			Введем также множество категорий $\mathcal{C}, ~|\mathcal{C}| = n_c$ элементов одежды, дальше называемых \textit{категориями}. \\
			Каждый объект принадлежит некоторой категории $C_i\in\mathcal{C}, i=\overline{1,n_c}$. \\
			Категорию объекта $X\in\mathcal{X}$ будем обозначать $C_X$. \\
			Множество всех объектов категории $C_i$ --- $\mathcal{X}_{C_i}$
			
			Некоторое подмножество $O = \{X_i\}_{i=1}^k\subset \mathcal{X}$ множества всех элементов будем называть \textit{образом}, если
			\begin{enumerate}
				\item $O\neq\{\O\}$
				\item $|O| \leqslant K$
				\item $\forall X_i, X_j \in O, i\neq j\longrightarrow C_{X_i} \neq C_{X_j}$
			\end{enumerate}
		    где $K$ -- определяемая задачей константа. 
			Множество всех образов обозначим $\mathcal{O}$. 
			Стоит заметить, что из такого определение следует, в частности:
		    $$O\in\mathcal{O}, O'\subset O \longrightarrow O'\in\mathcal{O}$$
		    
			Для элементов и образов будем рассматривать \textit{функции близости}
				$$S_X:~\mathcal{X}\times \mathcal{X}\longrightarrow [-1,1], ~~\forall X\in\mathcal{X}~S_X(X,X) = 1$$
				$$S_O:~\mathcal{O}\times \mathcal{O}\longrightarrow [-1,1], ~~\forall O\in\mathcal{O}~S_O(O,O) = 1$$
			Такой функцией может выступать например косинусное сходство в некотором латентном пространстве.
				
			Для оценки образов введем функцию \textit{оценки} или \textit{совместимости} его элементов: 
			$$\mathcal{S}:~2^\mathcal{X}\longrightarrow [0,1]$$
			 причем выполнено следующее:
			$$\forall O \in \mathcal{O}:~\mathcal{S}(O) > 0$$
			$$\forall O' \in 2^\mathcal{X} \setminus \mathcal{O}: \mathcal{S}(O') =0$$
			\textit{Совместимостью} или \textit{оценкой совместимости} образа $O$ будем называть результат применения функции совместимости к этому образу $\mathcal{S}(O)$
			
		\subsection{Описание рассматриваемых задач}
			\subsubsection{Оценка образа}
				Выше введена функция $\mathcal{S}$, ассоциирующая с каждым образом его оценку совместимости, однако вид такой функции неизвестен. Задача оценки образа -- это классическая задача регрессии:\\
				\begin{itemize}
					\item \textbf{Дано:}\\
						$\{O_1\dots O_n\}\subset \mathcal{O}$\\
						$\{\mathcal{S}(O_1)\dots\mathcal{S}(O_n)\}$
					\item \textbf{Требуется:}\\
					Найти наилучшую в некотором смысле аппроксимацию функции $\mathcal{S}$ функциями заданного класса, т.е. решить задачу оптимизации:\\
					$$\hat{\mathcal{S}}= \argmin_{S\in\mathscr{S}}\left[\frac{1}{N} \sum\limits_{i=1}^N\mathcal{L}(\mathcal{S}(O_i), S(O_i))\right]$$
					где $\mathcal{L}(\cdot, \cdot)$ некоторая метрика, например евклидова, а $\mathscr{S}$ -- рассматриваемое множество функций, например нейросети заданной архитектуры.
					
				\end{itemize}
				
			
			\subsubsection{Дополнение (восстановление) образа}
				Для решения задачи восстановления образа необходимо знать функцию совместимости или ее аппроксимацию. Предполагая ее известной, получаем следующую постановку:
				\begin{itemize}
					\item \textbf{Дано:}\\
					$O_n\in\mathcal{O}, ~|O| = n$ \\
					$k \in \mathbb{N}, ~k> n$ --- количество недостающих элементов\\
					$J\subset\mathbb{N},~|J| = m\geqslant k-n$ --- множество индексов категорий недостающих элементов\\
					$\{\hat{T_i}\}_{i=1}^{k-n}$ --- текстовые представления недостающих элементов, возможно пустые. В случае если предлагается только текстовое описание всего образа $T$, оно используется в качестве описания каждого элемента, т.е. $\forall i \in \overline{1,k-n}: ~T_i = T$.
					
					\item \textbf{Требуется:}\\
					Найти наилучшее в смысле максимизации функции оценки дополнение образа $O_n$ до $O_k\in\mathcal{O}, |O_k|=k$ элементами из категорий $\{C_j\}_{j\in J}$, т.е. решить следующую задачу:
					$$\{\hat{X_i}\}_{i=1}^{k-n}= \argmax_{\{X_i\}_{i=1}^{k-n}\in\left(\bigcup\limits_{j\in J}\mathcal{X}_j\right)^{n-k}} \left[\alpha \cdot \mathcal{S}\left(O_n\cup\{X_i\}_{i=1}^{k-n}\right) + (1-\alpha) \cdot \sum\limits_{i=1}^{k-n} S_X((I_i, T_i), (I_i, \hat{T_i}))\cdot\mathbb{I}\{\hat{T_i}\neq\O\}  \right]$$				
					здесь $X_i = (I_i, T_i)$, $\alpha\in[0,1]$. Второе слагаемое отвечает за соответствие предсказанного элемента предъявленному текстовому представлению и равно нулю, если представление пусто.
				\end{itemize}
			\subsubsection{Генерация образа}
				Задача генерации состоит в выборе образа произвольного размера, наиболее подходящего к предоставленному текстовому описанию. В терминах введенных выше получаем:
			
				\begin{itemize}
					\item \textbf{Дано:}\\
					$T$ --- текстовое описание образа.
					
					\item \textbf{Требуется:}\\
					Найти наилучший в смысле максимизации функции оценки образ $O\in\mathcal{O}$ элементы которого наилучшим образом соответствуют предложенному описанию $T$, т.е.:
					$$ \hat{O} = \argmax_{k,O = \{X_i\}_{i=1}^{k},  O\in\mathcal{O}} \left[\alpha \cdot \mathcal{S}(O) + (1-\alpha) \cdot \sum\limits_{i=1}^{k} S_X((I_i, T_i), (I_i, T))\cdot\mathbb{I}\{\hat{T}\neq\O\}  \right]$$				
					здесь $X_i = (I_i, T_i)$, $\alpha\in[0,1]$. 
					Стоит заметить, что если зафиксировать $k=1$, получаем обычную задачу поиска наиболее подходящего под описание элемента в коллекции.
				\end{itemize}
			
		\subsection{Обзор литературы}
			\subsubsection{Подходы к построению функций близости}
				При рассмотрении проблемы построения достаточно информативной функции от образов встает вопрос о том какие особенности структуры исходных данных могут быть полезны и на чем можно основывать выбор архитектуры. 
				
				Поскольку образ состоит из переменного числа первоначально независимых элементов, естественно перед рассмотрением образа независимо получать некоторое представление каждого его элемента. Кроме того, понятно, что операции с элементами внутри образа должны быть эквивариантны к перестановке элементов, поскольку на них не возникает естественного порядка. Развивая эту идею, можно сказать что каждому элементу присущ некоторый набор признаков, часть из которых может существенно влиять на совместимость, а значит декомпозиция элементов на признаки, моделирование их взаимосвязей а также взаимосвязей элементов между собой может помочь в построении оценки всего образа. 
				
				Подобным образом декомпозированная на разные масштабы задача может быть представлена например в виде графа, а значит одним из способов решения будут графовые нейронные сети. Такой подход в контексте оценки и подбора образов рассматривают в частности в статьях <<Fashion Retrieval via Graph Reasoning Networks on a Similarity
				Pyramid>> \cite{https://doi.org/10.48550/arXiv.1908.11754} и <<Hierarchical Fashion Graph Network for Personalized Outfit
				Recommendation>> \cite{https://doi.org/10.48550/arXiv.2005.12566}. \\
				
				В \cite{https://doi.org/10.48550/arXiv.1908.11754} авторы предлагают GRNet – модель для определения похожести элементов, которая обрабатывает несколько представлений изображения каждого элемента (текстовые описания в статье не рассматривается) в разном масштабе. Т.е. авторы использует еще один промежуточный уровень -- масштаб -- для построение латентного представления каждого элемента. 
				
				В предложенной модели для каждого элемента сначала с помощью GoogLeNet \cite{https://doi.org/10.48550/arXiv.1409.4842} создаются несколько представлений как раз и называемых масштабами, далее несколько вырезанных частей каждого из полученных представлений называются признаками. Считаются локальные векторы близости между соответствующими признаками в соответствующих масштабах, в конце осуществляется message passing \cite{https://doi.org/10.48550/arXiv.1704.01212} по полному графу, вершинами которого являются вычисленные векторы. Таким образом, вместо рассмотрения единого векторного представления, каждый элемент, пользуясь предполагаемой симметрией задачи, декомпозируют на несколько масштабов, а каждый масштаб на несколько признаков и моделируют их взаимодействие.
				
				Оставим за пределами нашего рассмотрения подробности процесса получения признаков, тогда пусть для элементов $X, Y\in \mathcal{X}$,  $\{x_l^i \in \mathbb{R}^{C\times 1}\}$ и $\{y_l^i \in \mathbb{R}^{C\times 1}\}$ векторные представления $i$-го локального признака в $l$ масштабе. Для каждого масштаба $l$ и номеров признаков $i$ и $j$ вектор локальной близости --- $s_l^{ij}$:
				$$s_l^{ij} = \frac{P|x_l^i-y_l^j|^2}{\|P|x_l^i-y_l^j|^2\|_2}$$
				где $P$ -- так называемая проекционная матрица с обучаемыми весами.\\
				Из этих векторов составляется граф, называемый авторами пирамидой. Далее для каждой пары вершин $s_{l_1}^{ij}$ и $s_{l_2}^{mn}$ определяется скаляный вес $w_p^{l_1ijl_2mn}$:
				$$w_p^{l_1ijl_2mn} = \frac{\exp((\mathbf{T}_{out}s_{l_1}^{ij})^\intercal(\mathbf{T}_{in}s_{l_2}^{mn}))}{\sum\limits_{l,p,q}\exp((\mathbf{T}_{out}s_{l_1}^{ij})^\intercal(\mathbf{T}_{in}s_{l}^{pq}))}$$ 
				где $\mathbf{T}_{in}, \mathbf{T}_{out}$ -- обучаемые матрицы.
				Тогда для $l_1=l_2$ это веса внутри одного масштаба, а для $l_1\neq l_2$ -- между разными, что позволяет им "сообщаться". Таким образом мы определили граф близости $G = (\mathbb{N},\mathbb{E})$, где $\mathbb{N} = \{s_l^{ij}\}$ а $\mathbb{E} = \{w_p^{l_1ijl_2mn}\}$.\\
				Далее вектора в каждой вершине обновляются по следующему правилу:
				$$\widehat{s}_{l_1}^{ij} =ReLU\left(\mathbf{W} \sum\limits_{l_2,m,n}w_p^{l_1ijl_2mn}s_{l_2}^{mn}\right)$$
				где $\mathbf{W}$ -- еще одна обучаемая матрица параметров. Итоговая оценка близости получается в дополнительной вершине графа, которая предварительно инициализируется некоторой простой функцией $s_g$:
				$$s_g = S_g(A(X), A(Y))$$
				где $A(.)$ --- например average pooling или max pooling по всем признакам во всех масштабах, а $S_g$ ---  например косинусное сходство.\\
				
				В \cite{https://doi.org/10.48550/arXiv.2005.12566} авторы используют схожий подход к декомпозиции для задачи рекомендации образов. Рассматривается иерархическая структура из трех уровней --- уровня элементов, уровня образов уровня пользователей. Для рассматриваемых пользователей, образов и элементов всех этих образов строится соответствующих трехуровневый граф с ребрами направленными с уровня элементов в уровень образов и из уровня образов в уровень пользователей. Далее, начиная с нижнего уровня, с помощью фактически чуть упрощенного подхода графовых сверточных сетей \cite{https://doi.org/10.48550/arXiv.1609.02907}, латентные представления элементов последовательно агрегируются в латентные представления на уровне образов и на уровне пользователей, которые непосредственно используются для рекомендации путем выбора для пользователя с представлением $u^*$ образа $\hat{O}$ по правилу $$\hat{O} = \argmax_{O\in \mathcal{O}}f(O)^\intercal u^*$$
				где $f(O)$ --- представление образа, полученное при подсчете в том же графе.
				
			\subsubsection{Восстановление, генерация и оценка образов}
				В задачах оценки, генерации и рекомендации образов, как и во многих других, хорошо показывают себя специальным образом обученные трансформерные \cite{https://doi.org/10.48550/arXiv.1706.03762} архитектуры. Заметим, что в силу отсутствия порядка на элементах и их признаках трансформер без позиционного кодирования \cite{https://doi.org/10.48550/arXiv.1706.03762} фактически эквивалентен graph attention network \cite{
				https://doi.org/10.48550/arXiv.1710.10903} с несколькими LayerNorm \cite{
				https://doi.org/10.48550/arXiv.1607.06450} и линейными слоями. Таким образом, при использовании этой архитектуры мы также неявно учитываем рассмотренную выше симметрию данных. 
				Варианты применение трансформеров для задач связанных с образами рассмотрены в частности в статьях \cite{https://doi.org/10.48550/arXiv.2303.02483} и \cite{https://doi.org/10.48550/arXiv.2204.04812}.\\
				
				В \cite{https://doi.org/10.48550/arXiv.2204.04812} авторы предлагают использовать архитектуру трансформера для обучения представления образа целиком. Полученное представление используется для оценки совместимости образа и восстановления образа с пропущенными элементами. В качестве токенов в трансформер подаются латентные представления элементов, т.е. фактически обрабатывается полный граф из всех элементов образа. Помимо изображений элементов, авторы также используют их текстовое описание и одновременно тренируют 2 энкодера для текстового и графического представления каждого объекта. Для задачи восстановления/рекомендации в модель также подается дополнительный токен, инициализированный случайный образом, после прохождения через модель агрегирующий в себе информацию из всех остальных и использующийся в итоге непосредственно для выбора ближайшего в смысле максимизации скалярного произведения дополняющего образ элемента.
				
				\includegraphics[scale = 0.8]{Literature review/OutfitTransfromer intro.png}
				
								
				(перерисовать картинку из статьи??)\\
				
				Предложенную модель обучают сначала для оценки совместимости образа, а затем заменяют последние линейные слои и дообучают получать представление образа для подбора подходящих элементов на основании полученного представления и текстового описания нового элемента. Из этого можно заключить, что учет внутренней структуры оказывается полезным и для оценки образа целиком, и для восстановления отдельных его частей, причем для разных задач возможно использовать одни и те же латентные представления элементов. \\
				
				Идею с общими внутренними представлениями для разных задач развивают авторы \cite{https://doi.org/10.48550/arXiv.2303.02483}. В статье рассматривается вопрос обучения мультимодального трансформера одновременно на несколько задач связанных с образами. 
				
				\begin{wrapfigure}{l}{0.5\linewidth}
					\includegraphics[scale = 1.0]{Literature review/FAME-ViL_acrhitecture.png}
				\end{wrapfigure}
				
				Основой архитектуры предложенной модели выступает предтренированный CLIP \cite{https://doi.org/10.48550/arXiv.2103.00020}. Для того, чтобы приспособить модель к выполнению различных задач рекомендации, распознавания и оценки образов авторы предлагают 2 вида адаптеров: TSA -- Task-Specific Adapter для обучения специфическим для каждой задачи особенностям и XAA -- Cross-Attention Adapter для обеспечения возможности взаимодействиями между различными модальностями, общий для всех задач. Для TSA предлагается ввести дополнительные линейные слои (AdaptMLP) после каждого self-attention блока параллельно с основными:
				$$z_l^{tsa}=s \cdot AdaptMLP(LN(z'_l))$$
				где $s$ -- Обучаемый множитель.\\
				В XAA используется дополнительный Multi-Head Cross Attention (MHXA) с группой линейных слоев после него:
				$$z_l^{xaa} = s\cdot AdaptMLP(LN(MHXA(z_l',y_l)))$$
				где $y_l$ выход self-attention слоя части сети для другой модальности.\\
				Далее полученные $z_l^{tsa}$ и $z_l^{xaa}$ аггрегируются с обычным выходом следующим образом:
				$$z_l = MLP(LN(z_l')) + z_l'+z_l^{tsa}+\epsilon\cdot z_l^{xaa},~\epsilon\in\{0,1\}$$
				$\epsilon$ -- барьерный множитель включающий или выключающий определенный адаптер для определенной задачи. 
				
				Рассматриваемая архитектура обучается на разные задачи в трех режимах Contrastive, Fusion и Generative с различными используемыми адаптерами и функциями потерь. 
				
				\includegraphics[scale = 0.7]{Literature review/FAME-ViL_modes.png}
				
				\begin{itemize}
					\item[]\textbf{Contrastive mode:}\\
					Этот режим используется для кросс-модальных рекомендаций (XMR) --- задачи выбора наиболее подходящего элемента по текстовому описанию и выбора наиболее подходящего описания элемента на изображении среди данных. Все XAA блоки отключены. Обучение производится на выборках элементов $\mathcal{X} \supseteq (\textbf{I}, \textbf{T}) = \{(I_1, T_1), \dots, (I_B, T_B)\}$, сначала части сети для соответствующей модальности по отдельности применяются к элементам каждой пары, формируя 2 итоговых унимодальных представления, а потом с помощью контрастной функции потерь \cite{https://doi.org/10.48550/arXiv.2004.11362} производится максимизация схожести получившихся унимодальных представлений.
					$$\mathcal{L}_{XMR} = \frac{1}{2} [\mathcal{L}_{InfoNCE}(\mathbf{T}, \mathbf{I}) + \mathcal{L}_{InfoNCE}(\mathbf{I}, \mathbf{T})]$$
					$$\mathcal{L}_{InfoNCE} = -\frac{1}{B}\sum\limits_{i=1}^{B}\log\frac{\exp(s(X_i, Y_i)/\tau)}{\sum_{j=1}^B\exp(s(X_i, Y_j)/\tau)}$$
					где $\tau$ -- обучаемая (???) температура. $s$ -- симметричная функция схожести $s(I_i, T_j) = f_\theta^{[c]}(I_i)^T\cdot f_\theta^{[c]}(T_j)$, где $f_\theta^{[c]}$ -- собственно нейросеть.
					\item[]\textbf{Fusion mode:}\\
					Используется для субкатегориального распознавания (SCR)и направляемых текстом рекомендаций (TGIR). И XAA, и TSA блоки включены. \\
					Задача SCR -- предсказание подкатегории для данного товара, основываясь на тексте и картинке. Исходя из специфики задачи, к выходу сети дополнительно добавляется классификатор, cross-entropy-loss которого и минимизируется:
					$$\mathcal{L}_{SCR} = -\mathbb{E}_{(I,T)\sim D}\log P\left(f_\theta^{[f]}(I, T)\right)$$
					Для TGIR --нахождения элементов похожих по изображению на данный и соответствующих текстовому описанию -- подход немного другой, поскольку необходимо получить представления отдельно для исходной картинки с текстовым описанием и целевой картинки, поэтому для $(\mathbf{I^r}, \mathbf{T})$ соответственно исходных картинок и текстовых запросов сеть запускается в $fusion$ режиме, а для целевых изображений $I^t$ в $contrastive$ режиме. Далее считается контрастная функция потерь вида
					$$\mathcal{L}_{TGIR} = \mathcal{L}_{InfoNCE}((I^r,T), I^t)$$
					
					\item[]\textbf{Generative mode:}\\
					Используется, например, для генерации описания к изображениям элементов. TSA блоки включены в обеих модальностях, XAA -- только image-to-text. Причем часть обрабатывающая входное изображение используется как энкодер, а вторая -- как декодер в авторегрессионном режиме.
				\end{itemize}
				
					
				
				
				
				
				

				
				
				
				%Отличительной особенностью рассмотренных %подходов является, согласно специфике задачи, %попытка в том или ином виде моделировать %взаимодействие многие ко многим между частями %внутренней структуры образов (элементами или %признаками).
			
					
			
			
			
	\bibliographystyle{plain}
	\bibliography{references}
			
	 
\end{document}